{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f40c2de-68bb-4346-b4c2-b8c079b62129",
   "metadata": {},
   "source": [
    "# Introduction to Apache Beam Python SDK & Google Dataflow\n",
    "\n",
    "![title](./image/beam_mascot.png)\n",
    "\n",
    "## prepared and presented by Setia Budi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf49c82-984a-47ab-a3e8-c91af42bc4cd",
   "metadata": {},
   "source": [
    "## What is Apache Beam?\n",
    "\n",
    "Apache Beam is a flexible programming SDK for building data processing pipelines that can handle batch processing, stream processing, and parallel processing in one. Its unified model allows developers to define and execute abstract data workflows to be deployed on one of any number of different data processing engines, such as Apache Flink, Apache Spark, Google Cloud Dataflow, and Kafka.\n",
    "\n",
    "BEAM -> Batch + strEAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badaa2d-3703-4a01-a1f1-dbeac309952b",
   "metadata": {},
   "source": [
    "## Apache Beam in a Glance\n",
    "\n",
    "![title](./image/learner_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31875f84-8458-4b3b-b3c7-80f4e95cde1e",
   "metadata": {},
   "source": [
    "## Basic Components\n",
    "\n",
    "### Pipeline\n",
    "A Pipeline encapsulates the entire data processing task, from start to finish. This includes reading input data, transforming that data, and writing output data.\n",
    "\n",
    "### PCollection\n",
    "A PCollection represents a distributed data set that your Beam pipeline operates on. The data set can be bounded, meaning it comes from a fixed source like a file, or unbounded, meaning it comes from a continuously updating source via a subscription or other mechanism. PCollections are the inputs and outputs for each step in your pipeline.\n",
    "\n",
    "### PTransform\n",
    "A PTransform represents a data processing operation, or a step, in your pipeline. Every PTransform takes one or more PCollection objects as the input, performs a processing function that you provide on the elements of that PCollection, and then produces zero or more output PCollection objects.\n",
    "\n",
    "### I/O Transforms\n",
    "Beam comes with a number of “IOs” - library PTransforms that read or write data to various external storage systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249d3ef-bc53-45bc-b7ac-e2737fb00d47",
   "metadata": {},
   "source": [
    "## Illustration for Pipeline, PCollection, and PTransform\n",
    "\n",
    "![title](./image/pcollection_ptransform.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fba91-e9f7-46a8-ae05-13726f7f1e00",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a47914f-2dd1-4e50-8619-d7ba6955429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487653d-40a2-492b-ba44-a3ae7c83e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40652653-2b40-4278-954e-7c3e9a2b9ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apache-beam\n",
    "!pip install apache-beam[gcp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f0125-63e4-422b-bc6b-51dba5ff5229",
   "metadata": {},
   "source": [
    "## Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c03713-ae8a-4562-8b8a-d73d91ccb381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149633CM,Marco,10,Accounts,1-01-2019\n",
      "212539MU,Rebekah,10,Accounts,1-01-2019\n",
      "231555ZZ,Itoe,10,Accounts,1-01-2019\n",
      "503996WI,Edouard,10,Accounts,1-01-2019\n",
      "704275DC,Kyle,10,Accounts,1-01-2019\n",
      "957149WC,Kyle,10,Accounts,1-01-2019\n",
      "241316NX,Kumiko,10,Accounts,1-01-2019\n",
      "796656IE,Gaston,10,Accounts,1-01-2019\n",
      "331593PS,Beryl,20,HR,1-01-2019\n",
      "560447WH,Olga,20,HR,1-01-2019\n",
      "222997TJ,Leslie,20,HR,1-01-2019\n",
      "171752SY,Mindy,20,HR,1-01-2019\n",
      "153636AS,Vicky,20,HR,1-01-2019\n",
      "745411HT,Richard,20,HR,1-01-2019\n",
      "298464HN,Kirk,20,HR,1-01-2019\n",
      "783950BW,Kaori,20,HR,1-01-2019\n",
      "892691AR,Beryl,20,HR,1-01-2019\n",
      "245668UZ,Oscar,20,HR,1-01-2019\n",
      "231206QD,Kumiko,30,Finance,1-01-2019\n",
      "357919KT,Wendy,30,Finance,1-01-2019\n"
     ]
    }
   ],
   "source": [
    "!{(\"head -n 20 ./example/dept_data.txt\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947b264-6cd0-4b3b-8e20-b0a8701a060e",
   "metadata": {},
   "source": [
    "## Case 1: Simple and Not So Useful Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24aae773-d4bd-4b35-9168-5f25882bbd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3eeabb3250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | beam.io.WriteToText(\"./output/output_data\")\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633ad37e-657e-4f8c-adb5-792959d0b2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149633CM,Marco,10,Accounts,1-01-2019\n",
      "212539MU,Rebekah,10,Accounts,1-01-2019\n",
      "231555ZZ,Itoe,10,Accounts,1-01-2019\n",
      "503996WI,Edouard,10,Accounts,1-01-2019\n",
      "704275DC,Kyle,10,Accounts,1-01-2019\n",
      "957149WC,Kyle,10,Accounts,1-01-2019\n",
      "241316NX,Kumiko,10,Accounts,1-01-2019\n",
      "796656IE,Gaston,10,Accounts,1-01-2019\n",
      "331593PS,Beryl,20,HR,1-01-2019\n",
      "560447WH,Olga,20,HR,1-01-2019\n",
      "222997TJ,Leslie,20,HR,1-01-2019\n",
      "171752SY,Mindy,20,HR,1-01-2019\n",
      "153636AS,Vicky,20,HR,1-01-2019\n",
      "745411HT,Richard,20,HR,1-01-2019\n",
      "298464HN,Kirk,20,HR,1-01-2019\n",
      "783950BW,Kaori,20,HR,1-01-2019\n",
      "892691AR,Beryl,20,HR,1-01-2019\n",
      "245668UZ,Oscar,20,HR,1-01-2019\n",
      "231206QD,Kumiko,30,Finance,1-01-2019\n",
      "357919KT,Wendy,30,Finance,1-01-2019\n"
     ]
    }
   ],
   "source": [
    "!{(\"head -n 20 ./output/output_data-00000-of-00001\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0739f-2bba-4d07-af03-fce704de66de",
   "metadata": {},
   "source": [
    "## Case 1.1: Simple and Not So Useful Pipeline, now with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf100bd-cdea-42f0-8b53-9917aaf19878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3eebc23cd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"WriteOutput\" >> beam.io.WriteToText(\"./output/output_data\")\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "751f8941-2954-46a7-ae42-57659c815986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149633CM,Marco,10,Accounts,1-01-2019\n",
      "212539MU,Rebekah,10,Accounts,1-01-2019\n",
      "231555ZZ,Itoe,10,Accounts,1-01-2019\n",
      "503996WI,Edouard,10,Accounts,1-01-2019\n",
      "704275DC,Kyle,10,Accounts,1-01-2019\n",
      "957149WC,Kyle,10,Accounts,1-01-2019\n",
      "241316NX,Kumiko,10,Accounts,1-01-2019\n",
      "796656IE,Gaston,10,Accounts,1-01-2019\n",
      "331593PS,Beryl,20,HR,1-01-2019\n",
      "560447WH,Olga,20,HR,1-01-2019\n",
      "222997TJ,Leslie,20,HR,1-01-2019\n",
      "171752SY,Mindy,20,HR,1-01-2019\n",
      "153636AS,Vicky,20,HR,1-01-2019\n",
      "745411HT,Richard,20,HR,1-01-2019\n",
      "298464HN,Kirk,20,HR,1-01-2019\n",
      "783950BW,Kaori,20,HR,1-01-2019\n",
      "892691AR,Beryl,20,HR,1-01-2019\n",
      "245668UZ,Oscar,20,HR,1-01-2019\n",
      "231206QD,Kumiko,30,Finance,1-01-2019\n",
      "357919KT,Wendy,30,Finance,1-01-2019\n"
     ]
    }
   ],
   "source": [
    "!{(\"head -n 20 ./output/output_data-00000-of-00001\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5acedb-1112-4c8c-a8a0-b4b6208fc243",
   "metadata": {},
   "source": [
    "## Case 2: Simple Pipeline with Simple Filter Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0527ea39-3020-4c5b-a3dc-b88734803eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3ee9b1e6d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "\n",
    "def split_row(element):\n",
    "    return element.split(\",\")\n",
    "\n",
    "\n",
    "def is_accounts(element):\n",
    "    return element[3] == \"Accounts\"\n",
    "\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(split_row)\n",
    "    | \"FilterAccounts\" >> beam.Filter(is_accounts)\n",
    "    | \"WriteOutput\" >> beam.io.WriteToText(\"./output/output_data\")\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d647b7a-02e7-4def-aefe-25ea1ce3e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['149633CM', 'Marco', '10', 'Accounts', '1-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '1-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '1-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '1-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '1-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '1-01-2019']\n",
      "['149633CM', 'Marco', '10', 'Accounts', '2-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '2-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '2-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '2-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '2-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '2-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '2-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '2-01-2019']\n",
      "['718737IX', 'Ayumi', '10', 'Accounts', '2-01-2019']\n",
      "['149633CM', 'Marco', '10', 'Accounts', '3-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '3-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '3-01-2019']\n"
     ]
    }
   ],
   "source": [
    "!{(\"head -n 20 ./output/output_data-00000-of-00001\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03b219-a5de-400b-a7cd-1126bde4fdf7",
   "metadata": {},
   "source": [
    "## Case 3: Simple Filter Transform using Lambda Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61738af5-48cb-49a8-85c5-3c8cc833c8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3f20b56040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"FilterAccounts\" >> beam.Filter(lambda record: record[3] == \"Accounts\")\n",
    "    | \"WriteOutput\" >> beam.io.WriteToText(\"./output/output_data\")\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938c239e-3f9d-46f5-b443-aacf27589439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['149633CM', 'Marco', '10', 'Accounts', '1-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '1-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '1-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '1-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '1-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '1-01-2019']\n",
      "['149633CM', 'Marco', '10', 'Accounts', '2-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '2-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '2-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '2-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '2-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '2-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '2-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '2-01-2019']\n",
      "['718737IX', 'Ayumi', '10', 'Accounts', '2-01-2019']\n",
      "['149633CM', 'Marco', '10', 'Accounts', '3-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '3-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '3-01-2019']\n"
     ]
    }
   ],
   "source": [
    "!{(\"head -n 20 ./output/output_data-00000-of-00001\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af810c91-6eae-403a-b691-b6a5a5e465e2",
   "metadata": {},
   "source": [
    "## Case 4: Using Google Dataflow as the runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43eda3-7b8c-42a1-937f-4eb9ef48a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "pipeline_options = PipelineOptions(\n",
    "    runner='DataflowRunner',\n",
    "    project='my-project-id',\n",
    "    job_name='unique-job-name',\n",
    "    temp_location='gs://my-bucket/temp',\n",
    ")\n",
    "\n",
    "p1 = beam.Pipeline(pipeline_options)\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"FilterAccounts\" >> beam.Filter(lambda record: record[3] == \"Accounts\")\n",
    "    | \"WriteOutput\" >> beam.io.WriteToText(\"./output/output_data\")\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c7b6b-288e-4ee6-9822-75e65ff8ca2c",
   "metadata": {},
   "source": [
    "## Case 5: Filter Transform with multiple arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73f21a2d-f5a2-4709-9c76-a0dd13398279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3f20b2ee80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "\n",
    "def split_row(element):\n",
    "    return element.split(\",\")   \n",
    "\n",
    "\n",
    "def has_role(element, role):\n",
    "  return element[3] == role\n",
    "\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(split_row)\n",
    "    | \"FilterAccounts\" >> beam.Filter(has_role, \"Accounts\")\n",
    "    # | \"FilterHR\" >> beam.Filter(has_role, \"HR\")\n",
    "    | \"WriteOutput\" >> beam.io.WriteToText(\"./output/output_data\")\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04dc52f8-5837-4533-ad31-9ba93ba0270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['149633CM', 'Marco', '10', 'Accounts', '1-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '1-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '1-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '1-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '1-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '1-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '1-01-2019']\n",
      "['149633CM', 'Marco', '10', 'Accounts', '2-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '2-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '2-01-2019']\n",
      "['503996WI', 'Edouard', '10', 'Accounts', '2-01-2019']\n",
      "['704275DC', 'Kyle', '10', 'Accounts', '2-01-2019']\n",
      "['957149WC', 'Kyle', '10', 'Accounts', '2-01-2019']\n",
      "['241316NX', 'Kumiko', '10', 'Accounts', '2-01-2019']\n",
      "['796656IE', 'Gaston', '10', 'Accounts', '2-01-2019']\n",
      "['718737IX', 'Ayumi', '10', 'Accounts', '2-01-2019']\n",
      "['149633CM', 'Marco', '10', 'Accounts', '3-01-2019']\n",
      "['212539MU', 'Rebekah', '10', 'Accounts', '3-01-2019']\n",
      "['231555ZZ', 'Itoe', '10', 'Accounts', '3-01-2019']\n"
     ]
    }
   ],
   "source": [
    "!{(\"head -n 20 ./output/output_data-00000-of-00001\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d66f41-3a9a-4eb5-bdea-aa22567208b3",
   "metadata": {},
   "source": [
    "## Case 6: Simple Pipeline with Simple Aggregation Transform\n",
    "###  `Count.Globally`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333abd5e-d969-4aa8-bd17-1f8ddbe0c599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3eebef07f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"FilterAccounts\" >> beam.Filter(lambda record: record[3] == \"Accounts\")\n",
    "    | \"Count all elements\" >> beam.combiners.Count.Globally()\n",
    "    | \"Print result\" >> beam.Map(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afb644b-32a0-4107-9173-cb269b0ffc2c",
   "metadata": {},
   "source": [
    "## Case 7: Simple Pipeline with Simple Aggregation Transform\n",
    "###  `Count.PerElement`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce32918e-952c-4dcc-b5af-7d1375de6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accounts', 278)\n",
      "('HR', 310)\n",
      "('Finance', 310)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3eebc23ee0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"Extract role column\" >> beam.Map(lambda record: (record[3]))\n",
    "    | \"Count all elements\" >> beam.combiners.Count.PerElement()\n",
    "    | \"Print result\" >> beam.Map(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adadc95b-4ce6-47c1-ad3b-fec250847e43",
   "metadata": {},
   "source": [
    "## Case 8: Adding key for each element using `WithKeys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0558d675-ea0d-4973-a47a-7f5213e97003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3eeab5ef40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"AddKey\" >>  beam.WithKeys(lambda record: record[3])\n",
    "    | \"WriteOutput\" >> beam.io.WriteToText(\"./output/output_data\")\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebdea835-a475-4daf-9c77-03cbac1e52fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accounts', ['149633CM', 'Marco', '10', 'Accounts', '1-01-2019'])\n",
      "('Accounts', ['212539MU', 'Rebekah', '10', 'Accounts', '1-01-2019'])\n",
      "('Accounts', ['231555ZZ', 'Itoe', '10', 'Accounts', '1-01-2019'])\n",
      "('Accounts', ['503996WI', 'Edouard', '10', 'Accounts', '1-01-2019'])\n",
      "('Accounts', ['704275DC', 'Kyle', '10', 'Accounts', '1-01-2019'])\n",
      "('Accounts', ['957149WC', 'Kyle', '10', 'Accounts', '1-01-2019'])\n",
      "('Accounts', ['241316NX', 'Kumiko', '10', 'Accounts', '1-01-2019'])\n",
      "('Accounts', ['796656IE', 'Gaston', '10', 'Accounts', '1-01-2019'])\n",
      "('HR', ['331593PS', 'Beryl', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['560447WH', 'Olga', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['222997TJ', 'Leslie', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['171752SY', 'Mindy', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['153636AS', 'Vicky', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['745411HT', 'Richard', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['298464HN', 'Kirk', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['783950BW', 'Kaori', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['892691AR', 'Beryl', '20', 'HR', '1-01-2019'])\n",
      "('HR', ['245668UZ', 'Oscar', '20', 'HR', '1-01-2019'])\n",
      "('Finance', ['231206QD', 'Kumiko', '30', 'Finance', '1-01-2019'])\n",
      "('Finance', ['357919KT', 'Wendy', '30', 'Finance', '1-01-2019'])\n"
     ]
    }
   ],
   "source": [
    "!{(\"head -n 20 ./output/output_data-00000-of-00001\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b1a8ab-977b-458e-8d48-7280db578744",
   "metadata": {},
   "source": [
    "## Case 9: Simple Pipeline with Simple Aggregation Transform\n",
    "###  `Count.PerKey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae39ed1-ecf2-4ed0-bdc1-3965aa511767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accounts', 278)\n",
      "('HR', 310)\n",
      "('Finance', 310)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3eebc23ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"AddKey\" >>  beam.WithKeys(lambda record: record[3])\n",
    "    | \"Count elements per key\" >> beam.combiners.Count.PerKey()\n",
    "    | \"Print result\" >> beam.Map(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3399cd3-60b8-491d-adaa-1a4e792572d2",
   "metadata": {},
   "source": [
    "## Case 10: Simple Pipeline with Simple Aggregation Transform\n",
    "###  `CombineGlobally(sum)`, `CombineGlobally(min)`, `CombineGlobally(max)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "687b47f2-8116-42c4-a1c2-8f126f966ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3f20a241f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"Cast to int\" >> beam.Map(lambda record: (int(record[2])))\n",
    "    | \"Sum of all elements\" >> beam.CombineGlobally(sum)\n",
    "    | \"Print result\" >> beam.Map(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497ecaa-c423-4dbf-9dd9-7307831a0e48",
   "metadata": {},
   "source": [
    "## Case 11: Simple Pipeline with Simple Aggregation Transform\n",
    "###  `Top.Smallest`, `Top.Largest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afb164a2-b1ba-452f-b05b-038bafa099d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3f20a24340>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"Cast to int\" >> beam.Map(lambda record: (int(record[2])))\n",
    "    | \"Top Smallest 5\" >> beam.combiners.Top.Smallest(5)\n",
    "    # | \"Top Largest 5\" >> beam.combiners.Top.Largest(5)\n",
    "    | \"Print result\" >> beam.Map(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90b323-83b1-41ba-b677-f0f53d135fe8",
   "metadata": {},
   "source": [
    "## Case 12: Simple Pipeline with Simple Aggregation Transform\n",
    "###  `CombinePerKey(sum)`, `CombinePerKey(min)`, `CombinePerKey(max)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9501ff5-78bd-4d5f-a4c1-98be6c683a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Marco', 310)\n",
      "('Rebekah', 310)\n",
      "('Itoe', 310)\n",
      "('Edouard', 310)\n",
      "('Kyle', 620)\n",
      "('Kumiko', 1240)\n",
      "('Gaston', 310)\n",
      "('Beryl', 1240)\n",
      "('Olga', 620)\n",
      "('Leslie', 620)\n",
      "('Mindy', 620)\n",
      "('Vicky', 620)\n",
      "('Richard', 620)\n",
      "('Kirk', 620)\n",
      "('Kaori', 1550)\n",
      "('Oscar', 620)\n",
      "('Wendy', 930)\n",
      "('Cristobal', 930)\n",
      "('Erika', 930)\n",
      "('Sebastien', 930)\n",
      "('Valerie', 930)\n",
      "('Dolly', 930)\n",
      "('Emily', 930)\n",
      "('Hitomi', 930)\n",
      "('Ayumi', 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3f213165e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    # | \"Cast to int\" >> beam.Map(lambda record: (record[3], int(record[2])))\n",
    "    | \"Map to Key Value\" >> beam.Map(lambda record: (record[1], int(record[2])))\n",
    "    | \"Calculate elements per key\" >> beam.CombinePerKey(sum)\n",
    "    | \"Print result\" >> beam.Map(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca739b08-3f99-4ae6-8918-50513b71eb82",
   "metadata": {},
   "source": [
    "## Case 13: Simple Pipeline with Simple Aggregation Transform\n",
    "###  `Mean.Globally`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecd7f629-eeb4-4b4f-8146-7d984d5cfd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.356347438752785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3f20ad22b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"Cast to int\" >> beam.Map(lambda record: (int(record[2])))\n",
    "    | \"Mean of all elements\" >> beam.combiners.Mean.Globally()\n",
    "    | \"Print result\" >> beam.Map(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437bc78-5d1a-4a38-88c5-a418d42f6356",
   "metadata": {},
   "source": [
    "## Case 14: Simple Pipeline with Simple Aggregation Transform\n",
    "###  `Mean.PerKey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12714252-f4f3-462d-ac5e-3a839649c823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accounts', 10.0)\n",
      "('HR', 20.0)\n",
      "('Finance', 30.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7f3f2136a430>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "p1 = beam.Pipeline()\n",
    "\n",
    "(\n",
    "    p1\n",
    "    | \"ReadFromText\" >> beam.io.ReadFromText(\"./example/dept_data.txt\")\n",
    "    | \"SplitRecord\" >> beam.Map(lambda record: record.split(\",\"))\n",
    "    | \"Cast to int\" >> beam.Map(lambda record: (record[3], int(record[2])))\n",
    "    # | \"Map to Key Value\" >> beam.Map(lambda record: (record[1], int(record[2])))\n",
    "    | \"Mean elements per key\" >> beam.combiners.Mean.PerKey()\n",
    "    | \"Print result\" >> beam.Map(print)\n",
    ")\n",
    "\n",
    "p1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on codespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663708d-0ecc-41c0-92bd-7bf7fbb8f5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
